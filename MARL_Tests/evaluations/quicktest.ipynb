{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Simple Markov Model – Evaluation Setup\n",
    "\n",
    "Simulate a communication model with two states: Working (W) and Failed (F) using transition probabilities. Track how these failures affect coordination and performance."
   ],
   "id": "9f1eb2f7f04e33a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T09:57:05.777528Z",
     "start_time": "2025-05-18T09:57:03.274570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from mpe2 import simple_spread_v3\n",
    "from failure_api.communication_models import BaseMarkovModel\n",
    "from failure_api.wrappers import CommunicationWrapper\n",
    "from pettingzoo.utils import aec_to_parallel\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 3\n",
    "episodes = 30\n",
    "seeds = [42, 123]\n",
    "max_cycles = 24\n",
    "\n",
    "agent_ids = [f\"agent_{i}\" for i in range(N)]\n",
    "# Transition matrix:\n",
    "# P[0] = [stay_disconnected, become_connected]\n",
    "# P[1] = [become_disconnected, stay_connected]\n",
    "simple_matrix = np.array([[0.8, 0.2],  # Disconnected → (D, C)\n",
    "                          [0.3, 0.7]])  # Connected → (D, C)\n",
    "\n",
    "markov_model = BaseMarkovModel(\n",
    "    agent_ids=agent_ids,\n",
    "    default_matrix=simple_matrix,\n",
    ")\n",
    "markov_env = simple_spread_v3.env(N=N, max_cycles=max_cycles)\n",
    "wrapped_markov_env = CommunicationWrapper(markov_env,\n",
    "                                          failure_models=[markov_model])\n",
    "\n",
    "parallel_markov = aec_to_parallel(wrapped_markov_env)\n",
    "\n",
    "all_rewards = []\n",
    "step_times = []\n",
    "episode_broken = False\n",
    "\n",
    "for seed in seeds:\n",
    "    for episode in range(episodes):\n",
    "        obs, _ = parallel_markov.reset(seed=seed)\n",
    "        total_reward = 0\n",
    "        start_time = time.perf_counter()\n",
    "        \n",
    "        for step in range(max_cycles):\n",
    "            if not parallel_markov.agents:\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                actions = {\n",
    "                    agent: parallel_markov.action_space(agent).sample() \n",
    "                    for agent in parallel_markov.agents\n",
    "            }\n",
    "                \n",
    "                obs, rewards, terminations, truncations, infos = parallel_markov.step(actions)\n",
    "                \n",
    "                total_reward += sum(rewards.values())\n",
    "            \n",
    "                if all(terminations.values()) or all(truncations.values()):\n",
    "                    break\n",
    "                \n",
    "            except KeyError as e:\n",
    "                if not episode_broken:\n",
    "                    print(f\"⚠️ Episode {episode} (Seed {seed}) interrupted due to KeyError on {e}\")\n",
    "                    episode_broken = True\n",
    "                break\n",
    "            \n",
    "        step_duration = (time.perf_counter() - start_time) / max_cycles\n",
    "        step_times.append(step_duration * 1000)\n",
    "        all_rewards.append(total_reward)\n",
    "        \n",
    "    print(\"=== Simple Markov Model Summary ===\")\n",
    "    print(f\"Total episodes: {len(all_rewards)}\")\n",
    "    print(f\"Avg Reward: {np.mean(all_rewards):.2f} ± {np.std(all_rewards):.2f}\")\n",
    "    print(f\"Avg Step Time: {np.mean(step_times):.3f} ms\")\n",
    "\n"
   ],
   "id": "7e9de4992b7153e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Episode 0 (Seed 42) interrupted due to KeyError on 'agent_0'\n",
      "=== Simple Markov Model Summary ===\n",
      "Total episodes: 30\n",
      "Avg Reward: -66.07 ± 6.72\n",
      "Avg Step Time: 1.925 ms\n",
      "=== Simple Markov Model Summary ===\n",
      "Total episodes: 60\n",
      "Avg Reward: -77.24 ± 13.73\n",
      "Avg Step Time: 1.698 ms\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Extended Markov Model\n",
    "Introduce richer state dynamics with three communication states, each with different masking effects to simulate partial degradation in communication.\n",
    "\n"
   ],
   "id": "91c0d19c8cb6fe88"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
